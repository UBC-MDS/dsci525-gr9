{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cb645c-1007-48b0-b711-646cd4671178",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step0 : Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20a54cd-25ef-4c55-b37e-337544a7aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8dcfd-eafe-408e-9638-9c479e5aef42",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step3 : Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4dd88-7d60-497c-95e1-d6ad4b0e24e7",
   "metadata": {},
   "source": [
    "### 3.1 Download the data from figshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938d1248-1864-4037-a243-031ada81be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger request to download data\n",
    "article_id = \"14096681\"\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figsharerainfall/\"\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  \n",
    "files = data[\"files\"]            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ac278-4239-41ff-8eaf-43f769527739",
   "metadata": {},
   "source": [
    "### 3.2 Extract the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c697532d-40a3-41f8-8390-8e6473c76524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file with downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3dc50d5-9c23-45ee-8c93-2536788f0776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.36 s, sys: 5.56 s, total: 8.92 s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_to_dl = [\"data.zip\"]\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20000eba-9dbe-4920-b098-fc26bbd593ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data into output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d9cfbd-b91f-4534-af44-85224ef9662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.07 s, sys: 716 ms, total: 7.79 s\n",
      "Wall time: 7.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3334e61-8cd9-4e43-981d-270d87481094",
   "metadata": {},
   "source": [
    "# Step4 : Combining data CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd2a20d-f0a6-4e08-a3e0-e51ff2e9f1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 58s, sys: 31.6 s, total: 9min 30s\n",
      "Wall time: 9min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "excluded_files = [\"figsharerainfall\\\\observed_daily_rainfall_SYD.csv\"]\n",
    "files = glob.glob('figsharerainfall/*.csv')\n",
    "files = list(set(files) - set(excluded_files))\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(\"/([^_]*)\", file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"figsharerainfall/combined_data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bc767f2-c49c-46a9-804f-ba478bcad488",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |       MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   6min 16s         |\n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |     3min 31s       |\n",
    "| Natalie    |              MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|        7min 8s    |\n",
    "| Nikita    |    Windows              |  16GB   |   12th Gen Intel(R) Core(TM) i7-1255U | Yes |   12min 49s         |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc0f635b-e0f7-4c3b-bbde-18965121a59e",
   "metadata": {},
   "source": [
    "Summary :\n",
    "\n",
    "- Having a better processor, a single state drive (as opposed to a hard disk drive) and more memory (aka. RAM) are all factors that can decrease the amount of time taken to perform this task of combining multiple CSV files into one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722a11d-97b2-4789-b4ed-3e072394b42f",
   "metadata": {},
   "source": [
    "# Step5 : Perform Simple EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9967be9f-6877-4da9-9794-8f9db4bb2bec",
   "metadata": {},
   "source": [
    "### 5.1 Investigate at least two approaches to reduce memory usage while performing the EDA (e.g., value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22ad21f-252d-4692-9c79-446ede52532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410ddc4-8168-4847-8cd7-f6ca63783068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.041885    9105987\n",
      "-32.984293    9105987\n",
      "-34.869110    9105987\n",
      "-30.157068    4553010\n",
      "-31.099476    4553010\n",
      "               ...   \n",
      "-33.487232     551880\n",
      "-33.490981     551880\n",
      "-36.281964     551880\n",
      "-30.696652     551880\n",
      "-30.700015     551880\n",
      "Name: lat_min, Length: 86, dtype: int64\n",
      "-32.041885    9105987\n",
      "-32.984293    9105987\n",
      "-34.869110    9105987\n",
      "-29.214660    6070680\n",
      "-33.000000    4690980\n",
      "               ...   \n",
      "-27.909065     551880\n",
      "-30.700015     551880\n",
      "-30.696652     551880\n",
      "-33.490981     551880\n",
      "-33.487232     551880\n",
      "Name: lat_max, Length: 89, dtype: int64\n",
      "144.375000    7589139\n",
      "151.875000    7589139\n",
      "148.125000    7589139\n",
      "140.625000    7174959\n",
      "153.125000    5794719\n",
      "               ...   \n",
      "144.140625     690300\n",
      "142.734375     690300\n",
      "141.328125     690300\n",
      "143.750000     551880\n",
      "153.750000     414180\n",
      "Name: lon_min, Length: 78, dtype: int64\n",
      "148.125000    7589139\n",
      "151.875000    7589139\n",
      "144.375000    7589139\n",
      "154.375000    5794719\n",
      "145.625000    5794719\n",
      "               ...   \n",
      "151.171875     690300\n",
      "152.578125     690300\n",
      "153.984375     690300\n",
      "143.750000     551880\n",
      "155.625000     414180\n",
      "Name: lon_max, Length: 79, dtype: int64\n",
      "CPU times: user 1min 19s, sys: 21.5 s, total: 1min 41s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"figsharerainfall/combined_data.csv\")\n",
    "print(df[\"lat_min\"].value_counts())\n",
    "print(df[\"lat_max\"].value_counts())\n",
    "print(df[\"lon_min\"].value_counts())\n",
    "print(df[\"lon_max\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6d5171-38ce-42ec-a2c8-7e39d822f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach1 - Select just columns we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee088e0-e94e-4498-9782-1d4ed03a32f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.041885    9105987\n",
      "-32.984293    9105987\n",
      "-34.869110    9105987\n",
      "-30.157068    4553010\n",
      "-31.099476    4553010\n",
      "               ...   \n",
      "-33.487232     551880\n",
      "-33.490981     551880\n",
      "-36.281964     551880\n",
      "-30.696652     551880\n",
      "-30.700015     551880\n",
      "Name: lat_min, Length: 86, dtype: int64\n",
      "-32.041885    9105987\n",
      "-32.984293    9105987\n",
      "-34.869110    9105987\n",
      "-29.214660    6070680\n",
      "-33.000000    4690980\n",
      "               ...   \n",
      "-27.909065     551880\n",
      "-30.700015     551880\n",
      "-30.696652     551880\n",
      "-33.490981     551880\n",
      "-33.487232     551880\n",
      "Name: lat_max, Length: 89, dtype: int64\n",
      "144.375000    7589139\n",
      "151.875000    7589139\n",
      "148.125000    7589139\n",
      "140.625000    7174959\n",
      "153.125000    5794719\n",
      "               ...   \n",
      "144.140625     690300\n",
      "142.734375     690300\n",
      "141.328125     690300\n",
      "143.750000     551880\n",
      "153.750000     414180\n",
      "Name: lon_min, Length: 78, dtype: int64\n",
      "148.125000    7589139\n",
      "151.875000    7589139\n",
      "144.375000    7589139\n",
      "154.375000    5794719\n",
      "145.625000    5794719\n",
      "               ...   \n",
      "151.171875     690300\n",
      "152.578125     690300\n",
      "153.984375     690300\n",
      "143.750000     551880\n",
      "155.625000     414180\n",
      "Name: lon_max, Length: 79, dtype: int64\n",
      "CPU times: user 51.3 s, sys: 7.27 s, total: 58.6 s\n",
      "Wall time: 59.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "use_cols = ['lat_min','lat_max','lon_min','lon_max']\n",
    "df = pd.read_csv(\"figsharerainfall/combined_data.csv\",usecols=use_cols)\n",
    "print(df[\"lat_min\"].value_counts())\n",
    "print(df[\"lat_max\"].value_counts())\n",
    "print(df[\"lon_min\"].value_counts())\n",
    "print(df[\"lon_max\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe228ef-b5d2-422a-993c-a86abba87bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach2 - Load data in  chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f3f33d-a770-417b-beca-3e9805bb9908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-36.467390    1932840\n",
      "-36.455696     965790\n",
      "-36.420966    1242540\n",
      "-36.281964     551880\n",
      "-36.277805     551880\n",
      "               ...   \n",
      "-30.157068    4553010\n",
      "-30.000000    2898000\n",
      "-30.000000    2345490\n",
      "-29.921967    1932840\n",
      "-29.900000    1379700\n",
      "Length: 86, dtype: int64\n",
      "-36.000000    1379700\n",
      "-35.532329    1932840\n",
      "-35.100000    1379700\n",
      "-35.020151    1242540\n",
      "-35.000000    3725820\n",
      "               ...   \n",
      "-28.421053     689850\n",
      "-28.354430     965790\n",
      "-28.125000     965790\n",
      "-27.909065     551880\n",
      "-27.906064     551880\n",
      "Length: 89, dtype: int64\n",
      "140.62500    7174959\n",
      "141.00000    1931580\n",
      "141.09375    1104480\n",
      "141.18750    2484540\n",
      "141.25000    1517670\n",
      "              ...   \n",
      "152.81250    1932840\n",
      "153.00000    1931580\n",
      "153.12500    5794719\n",
      "153.28125    1104480\n",
      "153.75000     414180\n",
      "Length: 78, dtype: int64\n",
      "141.25000     965790\n",
      "141.87500    5794719\n",
      "142.03125    1104480\n",
      "142.27500     965790\n",
      "142.31250    2484540\n",
      "              ...   \n",
      "154.21875    1104480\n",
      "154.37500    5794719\n",
      "154.68750    1932840\n",
      "155.00000    1931580\n",
      "155.62500     414180\n",
      "Length: 79, dtype: int64\n",
      "CPU times: user 1min 18s, sys: 6.75 s, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counts_lat_min = pd.Series(dtype=int)\n",
    "counts_lat_max = pd.Series(dtype=int)\n",
    "counts_lon_min = pd.Series(dtype=int)\n",
    "counts_lon_max = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figsharerainfall/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts_lat_min = counts_lat_min.add(chunk[\"lat_min\"].value_counts(), fill_value=0)\n",
    "    counts_lat_max = counts_lat_max.add(chunk[\"lat_max\"].value_counts(), fill_value=0)\n",
    "    counts_lon_min = counts_lon_min.add(chunk[\"lon_min\"].value_counts(), fill_value=0)\n",
    "    counts_lon_max = counts_lon_max.add(chunk[\"lon_max\"].value_counts(), fill_value=0)\n",
    "print(counts_lat_min.astype(int))\n",
    "print(counts_lat_max.astype(int))\n",
    "print(counts_lon_min.astype(int))\n",
    "print(counts_lon_max.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa293e2-c5b2-4354-9ac4-4021ebc1615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach3 - Change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43da707b-3d8f-43a1-8c93-3f5cbaeba593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64: 6001.33 MB\n",
      "Memory usage with float32: 3000.67 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {df[['lat_min','lat_max','lon_min','lon_max']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df[['lat_min','lat_max','lon_min','lon_max']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1e5d4-5c42-45a9-825a-8419f3eedbb8",
   "metadata": {},
   "source": [
    "### 5.2 Compare run times on different machines within your team and summarize your observations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cbb6829-eb42-45ed-9ab0-a2310df1a72d",
   "metadata": {},
   "source": [
    "Original data :\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |   MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   1min 6s         |\n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |    39.3s        |\n",
    "| Natalie    |    MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|           1m 47s |\n",
    "| Nikita    |    Windows              | 16GB    |  12th Gen Intel(R) Core(TM) i7-1255U  |  Yes   |            |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f9fde45-2c9b-4253-9d31-107897503d2f",
   "metadata": {},
   "source": [
    "Approach1 - Select just columns we use :\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |     MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   38.8s         |            \n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |     23.9s       |\n",
    "| Natalie    |   MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|1m 6s|\n",
    "| Nikita    |    Windows              | 16GB    |  12th Gen Intel(R) Core(TM) i7-1255U  |  Yes   |            |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c26c9ab-01e0-496c-917f-11f414d41df7",
   "metadata": {},
   "source": [
    "Approach2 - Load data in chunks :\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |     MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   57.3s|          \n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |     32.1s       |\n",
    "| Natalie    |    MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|1m 11s|\n",
    "| Nikita    |    Windows              | 16GB    |  12th Gen Intel(R) Core(TM) i7-1255U  |  Yes   |            |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19530318-6edf-4799-b237-9e677d3fa8eb",
   "metadata": {},
   "source": [
    "Summary :\n",
    "\n",
    "- In terms of run time, the approach of selecting just the columns needed was the fastest, as opposed to loading the data in chunks\n",
    "- With the size of our dataset, loading the data in chunks had a similar run time to simply loading the original data in. This is most likely due to the fact that the amount of data (i.e., the number of columns and rows) is the same in approach 2 but for approach 1, we are simply selecting the columns we need and thus less data is being loaded in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bd29f-68ca-47fd-9e27-b4421e3b8bf4",
   "metadata": {},
   "source": [
    "# Step6 : Perform Simple EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e03ffb1-6418-48ba-875a-dea337a755d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75699285-6ea8-4122-9493-96da21dff5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepathcsv = \"figsharerainfall/combined_data.csv\"\n",
    "filepathparquet = \"figsharerainfall/combined_data.parquet\"\n",
    "filepathparquetr = \"figsharerainfall/combined_data_r.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf11569-22c7-44a7-b63d-250126a83bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rpy2_arrow\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import pyarrow \n",
    "from pyarrow import csv\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afb6829-470c-465f-bd3d-1be1ba222a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 s, sys: 4.16 s, total: 27.3 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ds.dataset(filepathcsv, format=\"csv\")\n",
    "# Converting the `pyarrow dataset` to a `pyarrow table`\n",
    "table = dataset.to_table()\n",
    "# Converting a `pyarrow table` to a `rarrow table`\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5f080f6-cd52-4984-9eeb-705254cd8d91",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |  MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   23.9s|              \n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |            |\n",
    "| Natalie    |    MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|25.7s|\n",
    "| Nikita    |    Windows              | 16GB    |  12th Gen Intel(R) Core(TM) i7-1255U  |  Yes   |            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6be97e27-76ee-47ee-b4c0-8125418968f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 6 × 7\n",
      "  time                lat_min lat_max lon_min lon_max `rain (mm/day)` model     \n",
      "  <dttm>                <dbl>   <dbl>   <dbl>   <dbl>           <dbl> <chr>     \n",
      "1 1889-01-01 04:00:00   -36.2     -35    141.    142.        3.29e-13 ACCESS-CM2\n",
      "2 1889-01-02 04:00:00   -36.2     -35    141.    142.        0        ACCESS-CM2\n",
      "3 1889-01-03 04:00:00   -36.2     -35    141.    142.        0        ACCESS-CM2\n",
      "4 1889-01-04 04:00:00   -36.2     -35    141.    142.        0        ACCESS-CM2\n",
      "5 1889-01-05 04:00:00   -36.2     -35    141.    142.        1.05e- 2 ACCESS-CM2\n",
      "6 1889-01-06 04:00:00   -36.2     -35    141.    142.        3.29e- 2 ACCESS-CM2\n"
     ]
    }
   ],
   "source": [
    "%%R -i r_table\n",
    "print(head(r_table) %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f5c169-0a74-4e9c-a95f-716e46b1ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 85 × 2\n",
      "   lat_min       n\n",
      "     <dbl>   <int>\n",
      " 1   -36.2  322140\n",
      " 2   -35    782040\n",
      " 3   -33.8  966210\n",
      " 4   -32.5  322140\n",
      " 5   -31.2  322140\n",
      " 6   -30   1747830\n",
      " 7   -35.9  459900\n",
      " 8   -34.9  459900\n",
      " 9   -33.9  459900\n",
      "10   -32.9  459900\n",
      "# ℹ 75 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 2.73 s, sys: 2.47 s, total: 5.2 s\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "# Counting the number of rows with each unique value in the lat_min column\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table %>% count(lat_min)\n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "804fa20d-bcb5-4b12-81dd-9948697f93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 88 × 2\n",
      "   lat_max       n\n",
      "     <dbl>   <int>\n",
      " 1   -35   1241940\n",
      " 2   -33.8  966210\n",
      " 3   -32.5  322140\n",
      " 4   -31.2  322140\n",
      " 5   -30   2529870\n",
      " 6   -28.8  322140\n",
      " 7   -35.1  459900\n",
      " 8   -34.1  459900\n",
      " 9   -33.1  459900\n",
      "10   -32.1  459900\n",
      "# ℹ 78 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 2.06 s, sys: 1.95 s, total: 4.01 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "# Counting the number of rows with each unique value in the lat_max column\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table %>% count(lat_max)\n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b26b03f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 80 × 2\n",
      "   lon_max       n\n",
      "     <dbl>   <int>\n",
      " 1    142. 1103940\n",
      " 2    148. 2529713\n",
      " 3    152. 2529713\n",
      " 4    154. 1104030\n",
      " 5    144. 2529713\n",
      " 6    150  1242000\n",
      " 7    146. 1425960\n",
      " 8    142.  321930\n",
      " 9    145.  321930\n",
      "10    146.  321930\n",
      "# ℹ 70 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 5.34 s, sys: 2.37 s, total: 7.71 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "# Counting the number of rows with each unique value in the lon_max column\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table %>% count(lon_max)\n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1c2509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 79 × 2\n",
      "   lon_min       n\n",
      "     <dbl>   <int>\n",
      " 1    141. 2391653\n",
      " 2    142.  920070\n",
      " 3    144. 2529713\n",
      " 4    146. 1104030\n",
      " 5    148. 2529713\n",
      " 6    152. 2529713\n",
      " 7    150   920070\n",
      " 8    143.  321930\n",
      " 9    144.  321930\n",
      "10    145.  321930\n",
      "# ℹ 69 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 5.58 s, sys: 975 ms, total: 6.56 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "# Counting the number of rows with each unique value in the lon_min column\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table %>% count(lon_min)\n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ef3171d-4c30-4601-a78a-3537f316813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Length    Class        Mode       \n",
      "time          187541589 ChunkedArray environment\n",
      "lat_min       187541589 ChunkedArray environment\n",
      "lat_max       187541589 ChunkedArray environment\n",
      "lon_min       187541589 ChunkedArray environment\n",
      "lon_max       187541589 ChunkedArray environment\n",
      "rain (mm/day) 187541589 ChunkedArray environment\n",
      "model         187541589 ChunkedArray environment\n"
     ]
    }
   ],
   "source": [
    "%%R -i r_table\n",
    "suppressMessages(library(dplyr))\n",
    "summary(r_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e241e4cd-c077-44fc-b018-e803fd6b0da0",
   "metadata": {},
   "source": [
    "We decided to proceed with Arrow exchange to transfer data frame from Python to R because it is fast and efficient at transferring data across different languages. It also avoids the data to be copied from one buffer to another, therefore, there is no CPU is used in this process compared to Parquet or Pandas exchange. Also, the data types present in out data frame are fully supported by Arrow exchange. In addition, dplyr and many other R packages have great integration with Arrow, so it will be the best to work in R. \n",
    "\n",
    "Pandas exchange is not very suitable for large data files like this one since it requires loading the entire set into the memory all at once which may take really long time to process and there is no guarantee that is would be able to process the transfer due to its limitations. Parquet files are generally more complex and harder to work with due to their structure.\n",
    "\n",
    "**Short EDA Summary:**\n",
    "- The total number of rows (or the length of each column) in the data frame is: 187541589.\n",
    "- ChunkedArray is the class of each column, which means that each column is a large array that is split into chunks for more efficient processing.\n",
    "- 'environment' is the mode of each column, which means that each column is stored in memory as an R environment.\n",
    "- The columns are: \"time\" (timestamp), \"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/day)\" (numeric), \"model\" (string).\n",
    "- There are 87 unique values in the `lat_min` column.\n",
    "- There are 90 unique values in the `lat_max` column."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "525_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
