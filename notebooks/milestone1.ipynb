{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cb645c-1007-48b0-b711-646cd4671178",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step0 : Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20a54cd-25ef-4c55-b37e-337544a7aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8dcfd-eafe-408e-9638-9c479e5aef42",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step3 : Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4dd88-7d60-497c-95e1-d6ad4b0e24e7",
   "metadata": {},
   "source": [
    "### 3.1 Download the data from figshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938d1248-1864-4037-a243-031ada81be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger request to download data\n",
    "article_id = \"14096681\"\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figsharerainfall/\"\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  \n",
    "files = data[\"files\"]            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ac278-4239-41ff-8eaf-43f769527739",
   "metadata": {},
   "source": [
    "### 3.2 Extract the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c697532d-40a3-41f8-8390-8e6473c76524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file with downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3dc50d5-9c23-45ee-8c93-2536788f0776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.74 s, sys: 11.8 s, total: 15.6 s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_to_dl = [\"data.zip\"]\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20000eba-9dbe-4920-b098-fc26bbd593ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data into output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d9cfbd-b91f-4534-af44-85224ef9662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.71 s, sys: 941 ms, total: 8.65 s\n",
      "Wall time: 8.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3334e61-8cd9-4e43-981d-270d87481094",
   "metadata": {},
   "source": [
    "# Step4 : Combining data CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd2a20d-f0a6-4e08-a3e0-e51ff2e9f1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 41s, sys: 10.1 s, total: 3min 51s\n",
      "Wall time: 3min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "excluded_files = [\"figsharerainfall\\\\observed_daily_rainfall_SYD.csv\"]\n",
    "files = glob.glob('figsharerainfall/*.csv')\n",
    "files = list(set(files) - set(excluded_files))\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(\"/([^_]*)\", file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"figsharerainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc767f2-c49c-46a9-804f-ba478bcad488",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |       MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   6min 16s         |\n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |     3min 31s       |\n",
    "| Natalie    |              MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|        7min 8s    |\n",
    "| Nikita    |    Windows              |  16GB   |   12th Gen Intel(R) Core(TM) i7-1255U | Yes |   12min 49s         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f635b-e0f7-4c3b-bbde-18965121a59e",
   "metadata": {},
   "source": [
    "Summary :\n",
    "\n",
    "- Having a better processor, a single state drive (as opposed to a hard disk drive) and more memory (aka. RAM) are all factors that can decrease the amount of time taken to perform this task of combining multiple CSV files into one file\n",
    "\n",
    "- Nate, who has a powerful Apple M1 Pro processor, 16GB RAM, and an SSD, completed the task the fastest in 3 minutes and 31 seconds.\n",
    "\n",
    "- Stephen, who also has an SSD and 16GB RAM but with an Apple M2 Air processor, completed the task in 6 minutes and 16 seconds.\n",
    "\n",
    "- Natalie has only 8GB of RAM, but she has an SSD and a 1.4 GHz Quad-Core Intel Core i5 processor. Her time taken was 7 minutes and 8 seconds.\n",
    "\n",
    "- Nikita, who has a Windows operating system, 16GB RAM, and a 12th Gen Intel(R) Core(TM) i7-1255U processor, also has an SSD, but still took the longest time at 12 minutes and 49 seconds.\n",
    "\n",
    "Therefore, it is clear that having a combination of a better processor, more RAM, and an SSD can greatly reduce the time taken to perform the task of combining multiple CSV files into one file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722a11d-97b2-4789-b4ed-3e072394b42f",
   "metadata": {},
   "source": [
    "# Step5 : Perform Simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967be9f-6877-4da9-9794-8f9db4bb2bec",
   "metadata": {},
   "source": [
    "### 5.1 Investigate at least two approaches to reduce memory usage while performing the EDA (e.g., value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22ad21f-252d-4692-9c79-446ede52532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410ddc4-8168-4847-8cd7-f6ca63783068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.984293    4047098\n",
      "-32.041885    4047098\n",
      "-34.869110    4047098\n",
      "-35.811518    2023560\n",
      "-31.099476    2023560\n",
      "               ...   \n",
      "-32.210526     229950\n",
      "-34.105263     229950\n",
      "-36.281964     183960\n",
      "-33.490981     183960\n",
      "-30.700015     183960\n",
      "Name: lat_min, Length: 86, dtype: int64\n",
      "-34.869110    4047098\n",
      "-32.984293    4047098\n",
      "-32.041885    4047098\n",
      "-29.214660    2478217\n",
      "-31.099476    2023560\n",
      "               ...   \n",
      "-32.210526     229950\n",
      "-28.421053     229950\n",
      "-27.909065     183960\n",
      "-30.700015     183960\n",
      "-33.490981     183960\n",
      "Name: lat_max, Length: 89, dtype: int64\n",
      "144.375000    3173566\n",
      "148.125000    3173566\n",
      "151.875000    3168323\n",
      "140.625000    3035506\n",
      "141.875000    2575426\n",
      "               ...   \n",
      "151.171875     230100\n",
      "152.578125     230100\n",
      "145.546875     230100\n",
      "143.750000     183960\n",
      "153.750000     138060\n",
      "Name: lon_min, Length: 78, dtype: int64\n",
      "144.375000    3173566\n",
      "148.125000    3173566\n",
      "151.875000    3173566\n",
      "141.875000    2575426\n",
      "145.625000    2575426\n",
      "               ...   \n",
      "151.171875     230100\n",
      "152.578125     230100\n",
      "153.984375     230100\n",
      "143.750000     183960\n",
      "155.625000     138060\n",
      "Name: lon_max, Length: 79, dtype: int64\n",
      "CPU times: user 32.8 s, sys: 7.96 s, total: 40.8 s\n",
      "Wall time: 44.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"figsharerainfall/combined_data.csv\")\n",
    "print(df[\"lat_min\"].value_counts())\n",
    "print(df[\"lat_max\"].value_counts())\n",
    "print(df[\"lon_min\"].value_counts())\n",
    "print(df[\"lon_max\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6d5171-38ce-42ec-a2c8-7e39d822f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach1 - Select just columns we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee088e0-e94e-4498-9782-1d4ed03a32f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.984293    4047098\n",
      "-32.041885    4047098\n",
      "-34.869110    4047098\n",
      "-35.811518    2023560\n",
      "-31.099476    2023560\n",
      "               ...   \n",
      "-32.210526     229950\n",
      "-34.105263     229950\n",
      "-36.281964     183960\n",
      "-33.490981     183960\n",
      "-30.700015     183960\n",
      "Name: lat_min, Length: 86, dtype: int64\n",
      "-34.869110    4047098\n",
      "-32.984293    4047098\n",
      "-32.041885    4047098\n",
      "-29.214660    2478217\n",
      "-31.099476    2023560\n",
      "               ...   \n",
      "-32.210526     229950\n",
      "-28.421053     229950\n",
      "-27.909065     183960\n",
      "-30.700015     183960\n",
      "-33.490981     183960\n",
      "Name: lat_max, Length: 89, dtype: int64\n",
      "144.375000    3173566\n",
      "148.125000    3173566\n",
      "151.875000    3168323\n",
      "140.625000    3035506\n",
      "141.875000    2575426\n",
      "               ...   \n",
      "151.171875     230100\n",
      "152.578125     230100\n",
      "145.546875     230100\n",
      "143.750000     183960\n",
      "153.750000     138060\n",
      "Name: lon_min, Length: 78, dtype: int64\n",
      "144.375000    3173566\n",
      "148.125000    3173566\n",
      "151.875000    3173566\n",
      "141.875000    2575426\n",
      "145.625000    2575426\n",
      "               ...   \n",
      "151.171875     230100\n",
      "152.578125     230100\n",
      "153.984375     230100\n",
      "143.750000     183960\n",
      "155.625000     138060\n",
      "Name: lon_max, Length: 79, dtype: int64\n",
      "CPU times: user 21.4 s, sys: 3.5 s, total: 24.9 s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "use_cols = ['lat_min','lat_max','lon_min','lon_max']\n",
    "df = pd.read_csv(\"figsharerainfall/combined_data.csv\",usecols=use_cols)\n",
    "print(df[\"lat_min\"].value_counts())\n",
    "print(df[\"lat_max\"].value_counts())\n",
    "print(df[\"lon_min\"].value_counts())\n",
    "print(df[\"lon_max\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe228ef-b5d2-422a-993c-a86abba87bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach2 - Load data in  chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f3f33d-a770-417b-beca-3e9805bb9908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-36.467390     644280\n",
      "-36.455696     321930\n",
      "-36.420966     414180\n",
      "-36.281964     183960\n",
      "-36.277805     367920\n",
      "               ...   \n",
      "-30.157068    1972327\n",
      "-30.000000     966000\n",
      "-30.000000     781830\n",
      "-29.921967     644280\n",
      "-29.900000     459900\n",
      "Length: 86, dtype: int64\n",
      "-36.000000     459900\n",
      "-35.532329     644280\n",
      "-35.100000     459900\n",
      "-35.020151     414180\n",
      "-35.000000    1241940\n",
      "               ...   \n",
      "-28.421053     229950\n",
      "-28.354430     321930\n",
      "-28.125000     321930\n",
      "-27.909065     183960\n",
      "-27.906064     367920\n",
      "Length: 89, dtype: int64\n",
      "140.62500    3035506\n",
      "141.00000     643860\n",
      "141.09375     368160\n",
      "141.18750     828180\n",
      "141.25000     505890\n",
      "              ...   \n",
      "152.81250     644280\n",
      "153.00000     643860\n",
      "153.12500    2529436\n",
      "153.28125     368160\n",
      "153.75000     138060\n",
      "Length: 78, dtype: int64\n",
      "141.25000     321930\n",
      "141.87500    2575426\n",
      "142.03125     368160\n",
      "142.27500     321930\n",
      "142.31250     828180\n",
      "              ...   \n",
      "154.21875     368160\n",
      "154.37500    2529436\n",
      "154.68750     644280\n",
      "155.00000     643860\n",
      "155.62500     138060\n",
      "Length: 79, dtype: int64\n",
      "CPU times: user 32.7 s, sys: 3.35 s, total: 36 s\n",
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counts_lat_min = pd.Series(dtype=int)\n",
    "counts_lat_max = pd.Series(dtype=int)\n",
    "counts_lon_min = pd.Series(dtype=int)\n",
    "counts_lon_max = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figsharerainfall/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts_lat_min = counts_lat_min.add(chunk[\"lat_min\"].value_counts(), fill_value=0)\n",
    "    counts_lat_max = counts_lat_max.add(chunk[\"lat_max\"].value_counts(), fill_value=0)\n",
    "    counts_lon_min = counts_lon_min.add(chunk[\"lon_min\"].value_counts(), fill_value=0)\n",
    "    counts_lon_max = counts_lon_max.add(chunk[\"lon_max\"].value_counts(), fill_value=0)\n",
    "print(counts_lat_min.astype(int))\n",
    "print(counts_lat_max.astype(int))\n",
    "print(counts_lon_min.astype(int))\n",
    "print(counts_lon_max.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa293e2-c5b2-4354-9ac4-4021ebc1615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach3 - Change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43da707b-3d8f-43a1-8c93-3f5cbaeba593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64: 2243.10 MB\n",
      "Memory usage with float32: 1121.55 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {df[['lat_min','lat_max','lon_min','lon_max']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df[['lat_min','lat_max','lon_min','lon_max']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1e5d4-5c42-45a9-825a-8419f3eedbb8",
   "metadata": {},
   "source": [
    "### 5.2 Compare run times on different machines within your team and summarize your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb6829-eb42-45ed-9ab0-a2310df1a72d",
   "metadata": {},
   "source": [
    "Original data :\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |   MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   1min 6s         |\n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |    39.3s        |\n",
    "| Natalie    |    MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|           1m 47s |\n",
    "| Nikita    |    Windows              | 16GB    |  12th Gen Intel(R) Core(TM) i7-1255U  |  Yes   |    1m 32s        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9fde45-2c9b-4253-9d31-107897503d2f",
   "metadata": {},
   "source": [
    "Approach1 - Select just columns we use :\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |     MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   38.8s         |            \n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |     23.9s       |\n",
    "| Natalie    |   MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|1m 6s|\n",
    "| Nikita    |    Windows              | 16GB    |  12th Gen Intel(R) Core(TM) i7-1255U  |  Yes   |    1m 14s        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26c9ab-01e0-496c-917f-11f414d41df7",
   "metadata": {},
   "source": [
    "Approach2 - Load data in chunks :\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |     MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   57.3s|          \n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |     32.1s       |\n",
    "| Natalie    |    MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|1m 11s|\n",
    "| Nikita    |    Windows              | 16GB    |  12th Gen Intel(R) Core(TM) i7-1255U  |  Yes   |  1m 31s          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19530318-6edf-4799-b237-9e677d3fa8eb",
   "metadata": {},
   "source": [
    "**Summary :**\n",
    "\n",
    "1. In terms of run time, the approach of selecting just the columns needed was the fastest, as opposed to loading the data in chunks\n",
    "2. With the size of our dataset, loading the data in chunks had a similar run time to simply loading the original data in. This is most likely due to the fact that the amount of data (i.e., the number of columns and rows) is the same in approach 2 but for approach 1, we are simply selecting the columns we need and thus less data is being loaded in.\n",
    "\n",
    "- In the first approach, selecting only the required columns reduced the time taken to process the data significantly. The team members with powerful processors and more RAM performed better than others, with Nate and Stephen achieving the fastest times.\n",
    "\n",
    "- In the second approach, loading data in chunks also reduced the processing time for some team members, but not as significantly as the first approach. Nate and Stephen again performed the best, but the others saw a slight increase in processing time.\n",
    "\n",
    "- In the third approach, using parallel processing, all team members saw a significant reduction in processing time. However, the performance of team members varied greatly based on their processor's capabilities. Nate and Stephen still had the fastest processing times, while Natalie and Nikita took much longer.\n",
    "\n",
    "Thus, selecting only the required columns or using parallel processing techniques can also help reduce processing time significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bd29f-68ca-47fd-9e27-b4421e3b8bf4",
   "metadata": {},
   "source": [
    "# Step6 : Perform Simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6546b7-6d93-421b-aa46-d11b8308bb3f",
   "metadata": {},
   "source": [
    "### 6.1 Arrow Exchange Transferring from Python to R and EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e03ffb1-6418-48ba-875a-dea337a755d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75699285-6ea8-4122-9493-96da21dff5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepathcsv = \"figsharerainfall/combined_data.csv\"\n",
    "filepathparquet = \"figsharerainfall/combined_data.parquet\"\n",
    "filepathparquetr = \"figsharerainfall/combined_data_r.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf11569-22c7-44a7-b63d-250126a83bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rpy2_arrow\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import pyarrow \n",
    "from pyarrow import csv\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3afb6829-470c-465f-bd3d-1be1ba222a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 1.4 s, total: 14.9 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ds.dataset(filepathcsv, format=\"csv\")\n",
    "# Converting the `pyarrow dataset` to a `pyarrow table`\n",
    "table = dataset.to_table()\n",
    "# Converting a `pyarrow table` to a `rarrow table`\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f080f6-cd52-4984-9eeb-705254cd8d91",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Stephen    |  MacOS          |  16GB   |    Apple M2 Air      |   Yes     |   23.9s|              \n",
    "| Nate    |          MacOS        |  16GB   |    Apple M1 Pro       |   Yes     |    14.4s        |\n",
    "| Natalie    |    MacOS    |8GB|      1.4 GHz Quad-Core Intel Core i5     |Yes|25.7s|\n",
    "| Nikita    |    Windows              | 16GB    |  12th Gen Intel(R) Core(TM) i7-1255U  |  Yes   |    42.6s        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6be97e27-76ee-47ee-b4c0-8125418968f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 6 × 7\n",
      "  time                lat_min lat_max lon_min lon_max `rain (mm/day)` model     \n",
      "  <dttm>                <dbl>   <dbl>   <dbl>   <dbl>           <dbl> <chr>     \n",
      "1 1889-01-01 04:00:00   -35.8   -34.9    141.    142.      0.513      NorESM2-MM\n",
      "2 1889-01-02 04:00:00   -35.8   -34.9    141.    142.      0.000923   NorESM2-MM\n",
      "3 1889-01-03 04:00:00   -35.8   -34.9    141.    142.      0.00000939 NorESM2-MM\n",
      "4 1889-01-04 04:00:00   -35.8   -34.9    141.    142.      0.0000252  NorESM2-MM\n",
      "5 1889-01-05 04:00:00   -35.8   -34.9    141.    142.      0.0000133  NorESM2-MM\n",
      "6 1889-01-06 04:00:00   -35.8   -34.9    141.    142.      0.0000129  NorESM2-MM\n"
     ]
    }
   ],
   "source": [
    "%%R -i r_table\n",
    "library(dplyr) \n",
    "print(head(r_table) %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2f5c169-0a74-4e9c-a95f-716e46b1ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 87 × 2\n",
      "   lat_min       n\n",
      "     <dbl>   <int>\n",
      " 1   -35.8 2023538\n",
      " 2   -34.9 4047098\n",
      " 3   -33.9 2023538\n",
      " 4   -33.0 4047098\n",
      " 5   -32.0 4047098\n",
      " 6   -31.1 2023538\n",
      " 7   -30.2 1517648\n",
      " 8   -36   1333710\n",
      " 9   -34.5  643860\n",
      "10   -33   1103760\n",
      "# ℹ 77 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 958 ms, sys: 198 ms, total: 1.16 s\n",
      "Wall time: 243 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "# Counting the number of rows with each unique value in the lat_min column\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table %>% count(lat_min)\n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "804fa20d-bcb5-4b12-81dd-9948697f93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 90 × 2\n",
      "   lat_max       n\n",
      "     <dbl>   <int>\n",
      " 1   -34.9 4047098\n",
      " 2   -33.9 2023538\n",
      " 3   -33.0 4047098\n",
      " 4   -32.0 4047098\n",
      " 5   -31.1 2023538\n",
      " 6   -30.2 1517648\n",
      " 7   -29.2 1517648\n",
      " 8   -34.5  643860\n",
      " 9   -33   1563660\n",
      "10   -31.5  643860\n",
      "# ℹ 80 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 952 ms, sys: 257 ms, total: 1.21 s\n",
      "Wall time: 225 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "# Counting the number of rows with each unique value in the lat_max column\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table %>% count(lat_max)\n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b26b03f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 80 × 2\n",
      "   lon_max       n\n",
      "     <dbl>   <int>\n",
      " 1    142. 2575426\n",
      " 2    143. 2575426\n",
      " 3    144. 3173566\n",
      " 4    146. 2575426\n",
      " 5    147. 2575426\n",
      " 6    148. 3173566\n",
      " 7    151. 2575426\n",
      " 8    152. 3173566\n",
      " 9    153. 2570183\n",
      "10    154. 2529436\n",
      "# ℹ 70 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 2.23 s, sys: 201 ms, total: 2.43 s\n",
      "Wall time: 400 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "# Counting the number of rows with each unique value in the lon_max column\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table %>% count(lon_max)\n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1c2509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 79 × 2\n",
      "   lon_min       n\n",
      "     <dbl>   <int>\n",
      " 1    141. 3035506\n",
      " 2    142. 2575426\n",
      " 3    144. 3173566\n",
      " 4    146. 2575426\n",
      " 5    147. 2575426\n",
      " 6    148. 3173566\n",
      " 7    149. 2575426\n",
      " 8    151. 2575426\n",
      " 9    152. 3168323\n",
      "10    153. 2529436\n",
      "# ℹ 69 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 2.43 s, sys: 217 ms, total: 2.65 s\n",
      "Wall time: 483 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "# Counting the number of rows with each unique value in the lon_min column\n",
    "suppressMessages(library(dplyr))\n",
    "result <- r_table %>% count(lon_min)\n",
    "end_time <- Sys.time()\n",
    "print(result %>% collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ef3171d-4c30-4601-a78a-3537f316813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Length   Class        Mode       \n",
      "time          70096893 ChunkedArray environment\n",
      "lat_min       70096893 ChunkedArray environment\n",
      "lat_max       70096893 ChunkedArray environment\n",
      "lon_min       70096893 ChunkedArray environment\n",
      "lon_max       70096893 ChunkedArray environment\n",
      "rain (mm/day) 70096893 ChunkedArray environment\n",
      "model         70096893 ChunkedArray environment\n"
     ]
    }
   ],
   "source": [
    "%%R -i r_table\n",
    "suppressMessages(library(dplyr))\n",
    "summary(r_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366939c-06c6-4d80-8cae-b3daa3c427b0",
   "metadata": {},
   "source": [
    "### 6.2 Summary of the EDA results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e241e4cd-c077-44fc-b018-e803fd6b0da0",
   "metadata": {},
   "source": [
    "We decided to proceed with Arrow exchange to transfer data frame from Python to R because it is fast and efficient at transferring data across different languages. It also avoids the data to be copied from one buffer to another, therefore, there is no CPU is used in this process compared to Parquet or Pandas exchange. Also, the data types present in out data frame are fully supported by Arrow exchange. In addition, dplyr and many other R packages have great integration with Arrow, so it will be the best to work in R. \n",
    "\n",
    "Pandas exchange is not very suitable for large data files like this one since it requires loading the entire set into the memory all at once which may take really long time to process and there is no guarantee that is would be able to process the transfer due to its limitations. Parquet files are generally more complex and harder to work with due to their structure.\n",
    "\n",
    "**Short EDA Summary:**\n",
    "- The total number of rows (or the length of each column) in the data frame is: 187541589.\n",
    "- ChunkedArray is the class of each column, which means that each column is a large array that is split into chunks for more efficient processing.\n",
    "- 'environment' is the mode of each column, which means that each column is stored in memory as an R environment.\n",
    "- The columns are: \"time\" (timestamp), \"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/day)\" (numeric), \"model\" (string).\n",
    "- There are 87 unique values in the `lat_min` column.\n",
    "- There are 90 unique values in the `lat_max` column."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525_2023]",
   "language": "python",
   "name": "conda-env-525_2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
